{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b32d14b-a3af-45e4-8cfc-6227f0c7af59",
   "metadata": {},
   "source": [
    "**Install dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475672e0-860f-4aba-97e0-6543b97f593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U tensorflow-text\n",
    "# !pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b7a3a-71ed-419b-81cd-7dab02915131",
   "metadata": {},
   "source": [
    "**Python modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca5c6ea-9b42-4c17-938b-0bf7913c394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2aad0d-682d-4461-a186-4cb77112b13a",
   "metadata": {},
   "source": [
    "**Project dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3433a4e2-d5eb-40ab-8329-9380ae77875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from db import db\n",
    "\n",
    "from bert.handler import get_encoder_and_preprocess_handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d67dfd-3ce6-4af1-944a-79a8c0791b89",
   "metadata": {},
   "source": [
    "**Tensorflow hub settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a14eeb-7dbb-4a79-8b4f-916430523669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env():\n",
    "    \"\"\"This tells tensorflow to persis modle in specified directory,\n",
    "    otherwise, it is going to save to model files somewhere else(hard to find).\n",
    "    You can not download a model in other people's computer without global\n",
    "    vpn access.\n",
    "    \n",
    "    The first time to run this script, you should ensure global vpn access.\n",
    "    \"\"\"\n",
    "    tfhub_path = os.path.join(config.model_path,\"tfhub_modules\")\n",
    "    if not os.path.exists(tfhub_path):\n",
    "        os.makedirs(tfhub_path)\n",
    "        \n",
    "    os.environ['TFHUB_CACHE_DIR'] = tfhub_path\n",
    "    \n",
    "create_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e01989-2e63-4da5-abf0-13f748cda590",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db.read()\n",
    "keyword2index = {keyword:i for i, keyword in enumerate(data.topic.unique())}\n",
    "index2keyword = {v:k for k,v in keyword2index.items()}\n",
    "data['target'] = data['topic'].replace(keyword2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef8a045-5106-4504-be4d-7076db932aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "tfhub_handle_encoder, tfhub_handle_preprocess =get_encoder_and_preprocess_handlers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc16450-5f28-4b5b-addb-76ebb201d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a9f35c0-6db8-481f-9bc3-9db3cba96c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[  101,  2013, 16948,  1010,  1996,  2489, 12204,  5376,  2000,\n",
       "          9163,  5376,  2000,  3945,  1012, 12464,  1011, 11968,  8043,\n",
       "          1011,  6434,  1012,  6045, 22074,  1063, 15489,  1011,  2806,\n",
       "          1024,  2009, 27072,  1065,  1012, 12464,  1011, 11968,  8043,\n",
       "          1011,  6434,  4487,  2615,  1012,  6045, 22074,  1063, 11687,\n",
       "          4667,  1011,  2187,  1024,  1015,  1012,  1020,  6633,  1025,\n",
       "          7785,  1011,  3953,  1024,  1014,  1012,  1019,  6633,  1065,\n",
       "          1012, 12464,  1011, 11968,  8043,  1011,  6434,  1012,  6045,\n",
       "         22074,  1045,  1063, 15489,  1011,  2806,  1024,  3671,  1065,\n",
       "          1012, 12464,  1011, 11968,  8043,  1011,  6434,  1012,  6045,\n",
       "         22074,  1009,  4957,  1009,  1012,  6045, 22074,  1063,  7785,\n",
       "          1011,  2327,  1024,  1011,  1014,  1012,  1019,  6633,  1065,\n",
       "          2005,  1996, 16948,  6410,  1997,  2806,  7175,  2189,  1010,\n",
       "          2156, 16948,  1024,  6410,  1997,  2806,  1013,  2189,  1012,\n",
       "          2298,   102]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_preprocess_model([data.iloc[0]['article_content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f714083f-7392-4bf9-8bb8-7d86ab398034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data.article_content.values, data.target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e2d8c-8394-45cb-a534-3b10aeb204a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
